{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Building a Neural Network to recognize Quick Draw doodles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general idea of this notebook will be to try and test the solutions provided by Google AI and other kagglers to the classification problem linked to the Quick Draw dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google AI suggestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a Neural Network dataset introducting LSTM layers. Indeed, they want to take into account the notion of temporality by using layers that keep track of what happened before. They also do not want to use a Neural Network that would consider the input as an image by using 1D Convolutionnal Layers. It's worth a try ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutorial of Google AI's solution in Tensorflow right here : https://www.tensorflow.org/tutorials/sequences/recurrent_quickdraw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Considering the dataset as images only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But here, we will try to work on a simpler idea which consists in interpreting the vectors of coordinates of the dataset as images only. Thus, we could use classical Neural Networks architectures that would consist in a succession of 2D Convolutionnal, Max Pooling and Flatten Layers then a FC layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemple of such a solution in Tensorflow here : https://www.kaggle.com/gaborfodor/black-white-cnn-lb-0-75/notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To run only on Google Colab\n",
    "google_collab = False\n",
    "\n",
    "if google_collab:\n",
    "    from os.path import exists\n",
    "    from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "    platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "    cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
    "    accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
    "\n",
    "    !pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
    "    import torch\n",
    "\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/samimhirech/anaconda/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import keras.utils\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import models,transforms,datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = '../../data_quick_draw/'\n",
    "model_dir = '../output/model/'\n",
    "mapping_dir = '../output/mapping/'\n",
    "results_dir = '../output/results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "axe = pd.read_csv(os.path.join(data_dir, 'axe.csv'), \n",
    "                  index_col='key_id', \n",
    "                  nrows=100).drop(['countrycode', 'recognized', 'timestamp'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "axe.drawing = axe.drawing.map(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "first_ten_ids = axe.iloc[:5].index\n",
    "axe_images = axe.loc[first_ten_ids, 'drawing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAADFCAYAAABaSzmEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLSyjmwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x102701be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAADFCAYAAABaSzmEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZLhs/T1vAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x120769f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAADFCAYAAABaSzmEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEaZJREFUeJzt3X2wXVV5x/Hvw0sC8iYqiIIQReVNIVaigGijaX0Zp9o6\nOrZlWls77bSjlakztbVVarVTnLa2xZZpK7Zj0bZ2qFNnHNHBghGKiDdCFQFfEG+0YAIBoZAQAsnT\nP9Y6nHOTe5OQe/Y9++z9/cycWTf3nLv3AsJvr/vstdeKzESS1F37TboDkqRmGfSS1HEGvSR1nEEv\nSR1n0EtSxxn0ktRxBr0kdZxBL0kdZ9BLUscZ9JLUcQa9JHWcQS9JHWfQS1LHGfSS1HEGvTTlIuLs\niHh3RJw96b6oncL16KXpFRHnAldRBm3bgDWZed1ke6W2cUQvTamIOA74OHAgsH9tV0+yT2ong16a\nQhHxGuB/gKOBrK9HgLUT7JZayqCXpkhEHBARFwKXA3cAP0Ep3dyDZRstwKCXpkQt1XwR+H3gI8BZ\nmflt4GZgmSGvhRww6Q5I2rOIeDWlHn8QcF5m/uvI2xuAwyPi4Mx8aCIdVKs5opdaLCLOjYi1wOeA\nO4Ezdwp5KEEP8NSl7JumhyN6qWUiIoDnAG+hlGn2Ax4F3lFLNTsbBP0xwOxS9FHTxaCXJiwi9gdO\nB1468ppvdH4O8KV5vj8a9NIuDHppiUXEcmAVw1B/CXB4fXs98AXgauAB4J8o8+N3N3XSoNduGfRS\nwyLiMOBsSqi/DHgxsLy+fQvwb8A1wDWZ+YOdfnY95SGotbuZVXM3ZR69Qa95GfTSmEXEUcC5DEfs\nL6A8uboduBG4mBLs/52Zm3Z3rBruu502mZmPRsQmDHotwKCXFikijqeM1AfBfkp9aytwPXAhpRTz\nlcx8oKFubMCg1wIMeulxqDNiTmZYhnkpcHx9+37gWuBSyoh9XWY+vERdM+i1IINe2o2IOABYydwZ\nMU+pb2+kjNT/ghLsN2Xm9kn0kxL0z53QudVyBr00IiIOAl7EcLR+DnBofft24LOUUL8auC3bs873\nBuCYiIgW9UktYdCr1yLiCEqYD0oxq4Bl9e1vMizDXJOZd0ykk3tnA2Umz+GUEpL0GINevRIRT2Vu\nGeYMhk+efg34MGW0fm1m3jupfu6D0bn0Br3mMOjVWfXG6Qrm3jgd1LEfokxb/AAl2K/PzM0T6Oa4\njAb9fMskqMcMenVGROwHnMpwtP4y4Nj69n2UEsxHa3tDZm6bRD8bsrG2zrzRLgx6Ta06Yv8V4E2U\nG6anAU+qb9/J8KbpNcDNmbljAt1cKi6DoAUZ9JpKEfEK4K+B59dvJWVGzKco4f79ns0++TFlPRyD\nXrtwPXpNlbo++xeBK4ETgMEofTvw5cz8WGbe3rOQp/62shGDXvMw6DUVIuJFEfF5ShnmFOB84HXA\nw5QZM26M7dOxWoClG7VaRKwE3g/8DGUD7HcBF2fmlvr+Gva8umNfbACOm3Qn1D4GvVopIk4D3ge8\nkTJj5j3Ah3deFGxvVnfskQ3AmZPuhNrHoFerRMRzgT8CfgF4kDLP/S8z876Jdmw6bASOioj9J7jm\njlrIoFcrRMQzgfcCv0ypu/8Z8OeZec9EOzZdNlDWvX8ycNeE+6IWMeg1URFxHKUs82uUmTN/A3ww\nMzfu9gc1n9G59Aa9HuOsG01ERBwTERcBtwFvBS4BTszM3zHk95kPTWlejui1pOo2e+8C3kZZJfJj\nwJ9k5uwEu9UVBr3mZdCrcRFxNvBqyk5MbwQOAT4BvD8zb5tk3zrGoNe8DHo1pi4y9hbgIwz/rl0J\n/HZm3jqxjnVUZj4YEZsx6LUTg15jFRFPA14JvAr4aYbb7kG52XqlId8on47VLgx67ZNajllN2Qz7\nQEqwvwo4vX5kI/A54HvA79XPuExB81zvRrsw6PW41ZBfSwnvGHlrM/Dx+vpiZj5aP38FLlOwVDZQ\n1gKSHhM9W+RPYxARfwf85h4+lsC9wN07ve6a53t3A5sy85Gm+twXEXEx8POZ+eRJ90Xt4Yhe4/DP\nwIeAo+rr6JGvB69TKDs+PZm5vwU8JiLuY/cXg9GLxabMfLixf6LptQF4UkQs99+PBgx67YtLgV8F\nllNG7h/JzJv25gcjYn/KLlDzXQxGX88GzqHczJ33wb6I+D92fzGY873MfOjx/6NOncEUy6OBH06y\nI2oPg16PW2ZeFxEvB95JmRd/IvDlvfzZ7QzDd4/qFM0jWfiCMLhgnEBZufEoFvh7Xace7k0ZafB6\nPtN3b2F0Lr1BL8AavRahhvB1wDOAk3ZeQngS6j6yRzD/xWCh1/I9HPZR4I+Bj2Xm/zbT8/GIiFXA\nV4HXZeZnJt0ftYNBr0WJiLMoYX9hZv7BpPvzeNULw6HsekF4E2W66M73E35A+e3l2vq6aTC7qA0i\n4hmUPv5GZl4y6f6oHQx6LVpEXAq8GTg1M7836f6MQ51CeiXD+f9vAw4DXlJfx9aPPghczzD4r8/M\n+5e8w1VELAe2Ahdk5gcm1Q+1i0GvRYuIpwPfAf4rM3920v0Zl5GHwubU6OtvAcdTbhYPgv90yk3j\nBG5iGPxfBmaXcrPyepP6ZuCdU3RvQQ0y6DUWEfFu4E+BV2bmFybdn6UWEYcBL2YY/GdRfgMA+BFz\ng//Gpp4ZqBena+sftwJrDHsZ9BqLiDiIMorcCqzs+8NPdRrp8xgG/0soM4MAHqLcMB0E/3WZee8Y\nzrkG+F3KWkNBuYl8QWZeuNhja7oZ9BqbiHg98Gng/Mz88KT70zYRcSxzyz0voGz9B3ALc2/y3rZQ\nuScijgZOBU6rr1OBM4AnjnxsB2URubd5U1YGvcam1q6voMxnf05mbppwl1otIg4BVjEM/rMZhvVm\n4BvA1+vXzwJWUp4pGA30QT3+AOCFzH24LLF8Iwx6jVlEnEoJqEsy87cm3Z9pEhE/BVwAnMsCy0RQ\nRul/C1xOCfg7MzN3miUE5TcFyzcCfDJWY5aZt9SFtd4eEX+fmV+fdJ+mQQ3qz1K2VxzYAXwSOAj4\nOUpwJ7AxM68Y/fn6tPIayiyhTZSLwTLKhWFtw91Xyxn0asL7gPOAiyLi5Us5tXCKrWbu/4+DGvta\n4JvAa9jDmv61PHMdQETcQblw/INlG827WJS0GJn5Y+A9wE9S1sLRnt1ICXZqG5Rgv6h+bw2lrLNX\n9fbMvJyy1s3R4++qpo01ejWiTi+8gXLj8OSerBy5W3VtoOMpSzafApw80u685eJgNs4+19gj4lPA\nGZn57MX0W9PP0o0akZnbI+IdlDLDRRHxfaZrFch9Vp8peA67hvlJwMEjH90E3Ar8Z22fBbydUo//\ndxa//eI64A0RcWT9LUs9ZdCrMZn5pYi4Cvh1yih1W0R0ZqpfRBzJMMhHQ/2ZDMuiCaynBPlVwLfq\n19/aefppRJxfv7yWUqpZzeIujjO1PRPo3dPKGjLo1bR1wCsopYhllPCamqCvzwYcx9wgH3z91JGP\nPkxZ7+cG4F+oYQ58JzO37OXpBsslPzx6Y3UR1tV2FQZ9rxn0atqngfMpIbYfZQnd1omIZZRdrXYO\n85OBQ0Y+eh8lxD/LcHR+K2Xhsu0szmNBv8jjAJCZ90XEdylBrx4z6NWokd2o3kyZcnlxRPwwM6+e\nRH8i4nDm1s0HoX4iwxugUGas3Ar8I8PR+a3AXQ1OF11GKfUs9oIxaoYy+0k9ZtCrcYMyRET8FfB5\n4IqIOC8zPzWuc9RZPofW12G1PYdS636EMvvnFODpIz/2CPBdyjz1yxiG+bcz88Fx9e1xWE4p24zz\nQrIO+MWIeFpm/miMx9UUMei1ZDJzfUScC3wGuKwG/3bKkgnfZ25IL9Qu9N7B7N4tlDr1YzdDgdtb\ntsrmcsZUthkxekPWrQV7yqDXksrMe+qaLldQNhffk+3AA5SdnEbbexb4/qB9NaVUtD9lLvonpmC9\nl2WMP+hvpDxluwqDvrcMei25zNwSEZ+jrNa4HyXMLwU+yq6BvU+ljIiYpez7uti56EtpObBtnAfM\nzM0RcTPekO01g16TchXwhwyD+JJxzq/faZGvaXlQq4nSDZTyzesjIlx3qJ8Mek3EUgTxmOaiL6Wm\ngn4d8FZgBeVeiHrGoNfETGEQN62JGj3MvSFr0PeQq1dK7TH2Gn31jXpc6/Q9ZdBL7dFI6SYzt1G2\nJDToe8qgl9qjqdINlPLNC+tSyeoZ/6NL7dFU6QZK0B9GWSpZPWPQS+3R1KwbGK5keWZDx1eLGfRS\nexwBnFg3Ch+3W4HNWKfvJYNeaoEa7scCpwNXjjvs6xLKN2DQ95JBL7XDasqG4INNwVc3cI4ZYGVE\nHNjAsdViBr3UDmsZrkPf1No8M8BBwPMaOLZazKCXWqA+JXwZJeSb2lfXG7I9ZdBL7fEVStnmtoaO\n/z3gx1in7x2DXmqP2dquaOLgdeXKdRj0vWPQS+0xW9sTGjzHDPD8iNjTjlzqEINeao/1tV3R4Dlm\nKLturWzwHGoZg15qicy8D7if5kf0YPmmVwx6qV3W0+yI/k5gA8686RWDXmqXWRoc0dcbsjM4ou8V\ng15ql1lgRUREg+eYAU6KiMMbPIdaxKCX2mU9ZTnhJzZ4jhnKUgsfamgBNbWMQS+1y2xtVzR4jsH/\n92+lgQXU1D4GvdQuSzHFchDs+9HcAmpqEYNeapfZ2jY5xXKw5s0OmltATS1i0Evtci9lg5AVDZ7j\nW7W9jOYWUFOLGPRSi9Tpj7M0O6J/Qm0/acj3g0Evtc8szY7oB0G/pcFzqEUMeql91rM0I3qDvicM\neql9ZoEjG3ygyaDvGYNeap/BFMumRvWDoN/c0PHVMga91D6ztV3R0PEd0feMQS+1T9MPTRn0PWPQ\nS+1zF7CV5ks3Bn1PGPRSy4zMpV/R0CkGQb+1oeOrZQx6qZ2anGL5BGBLvaCoBwx6qZ1maXZEb9mm\nRwx6qZ3WA0+JiEMaOPYhGPS9YtBL7TRb2ybKN47oe8agl9pptrYrGji2Qd8zBr3UTk0+HWvQ94xB\nL7XTBmAbjug1Bga91EKZuQP4AY7oNQYGvdReszii1xgY9FJ7NfXQlEHfMwa91F6zwDERcdCYj2vQ\n94xBL7XXbG2PH/NxDfqeMeil9hr7csURcSBwIAZ9rxj0UnvN1nbFGI95cG0N+h4x6KX2uhN4lPHe\nkHUt+h4y6KWWysztlE1IXhsRZ4/psIOgf8UYj6mWM+illqpBfAxwBnDlmIJ5cIw3jPGYajmDXmqv\n1UDUrw+sf16sVbXdb4zHVMsZ9FJ7rQV21K8fqX9erP+o7Y4xHlMtF+4mJrVXRFwOnAW8NjOvG9Mx\nv0mp1Z83rmOq3RzRS+12N3D/mAN5LXAU8NUxHlMtZtBL/TMDHAqcNOmOaGkY9FL/zNR21W4/pc4w\n6KX++TawGThz0h3R0jDopZ6pD2J9DUf0vWHQS/00A6yMiGWT7oiaZ9BL/TQDLAdOm3RH1DyDXuqn\ndbW1fNMDBr3UT7cD92LQ94JBL/VQlkfi12HQ94JBL/XXDPC8iDh4j5/UVDPopf5aB+wPrJx0R9Qs\ng17qL5+Q7QmDXuqpzLwD+BE+Idt5Br3Ub96Q7QGDXuq3GeCkiHif2wp2l0Ev9dsDlO0K34t7yHaW\nQS/12zG1dQ/ZDjPopX67qrbuIdthBr3Ub1fX9gvAGveQ7SaDXuq3h4EEvmrId5dBL/VYXfNmC/CE\nSfdFzTHoJRn0HWfQS3oIg77TDHpJjug7zqCXZNB3nEEvyaDvOINekkHfcQa9pC2Au0x1mEEvyVk3\nHWfQS+12FHBEw6tKHgoc7cqV3RXlwThJbVOD9xrKvq7bgA8Ct435NM8G3kMZ9D2E69100gGT7oCk\nBa1m+Fv3MuCChs83WKbYoO8Yg15qr7XAVkrIPwL8EnDjmM/xAuDjlCxwmeKOsnQjtVgt36wG1jZV\nUlmKc2iyDHpJ6jhn3UhSxxn0ktRxBr0kdZxBL0kdZ9BLUscZ9JLUcQa9JHWcQS9JHWfQS1LHGfSS\n1HEGvSR1nEEvSR1n0EtSxxn0ktRxBr0kdZxBL0kdZ9BLUscZ9JLUcQa9JHWcQS9JHWfQS1LHGfSS\n1HEGvSR1nEEvSR1n0EtSxxn0ktRxBr0kdZxBL0kd9//YPyu2DwbrmgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x120dbae48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAADFCAYAAAC4lyL9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x124122e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAADFCAYAAABaSzmEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1241bda90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for index, axe_drawing in enumerate(axe_images, 0):\n",
    "    \n",
    "    plt.figure(figsize=(6,3))\n",
    "\n",
    "    for x,y in axe_drawing:\n",
    "        plt.plot(x, y, marker='.', color='black')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.axis('equal')\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming data : from strokes to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BASE_SIZE = 256\n",
    "\n",
    "def draw_cv2(raw_strokes, size=256, lw=6):\n",
    "    img = np.zeros((BASE_SIZE, BASE_SIZE), np.uint8)\n",
    "    for stroke in raw_strokes:\n",
    "        for i in range(len(stroke[0]) - 1):\n",
    "            _ = cv2.line(img, (stroke[0][i], stroke[1][i]), (stroke[0][i + 1], stroke[1][i + 1]), 255, lw)\n",
    "    if size != BASE_SIZE:\n",
    "        return cv2.resize(img, (size, size))\n",
    "    else:\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABkhJREFUeJzt3d1u4joYhlGyNfd/y9lHSFVfUhIS25/DWmcz6rQU8IPt\n/MyyrusD4Kf/Rj8AoB5hAIIwAEEYgCAMQBAGIAgDEIQBCMIAhH+jH8Dj8Xgsy+L0y4ltnT27LEvn\nR8Jf1nXd/YKUCAP3tK7ryzi8ComI1CIMNLX3Wpzn1wlEDcJAKT9DIhLj2HzkFFfn3pMw8LHWURCd\ncUqFwRsBaiixx/AzCNaYczgb8edr68OgphJh2GKnuq5lWQ4P6levo0DUVDoMT45717J3EHuN5lVq\nj+EInzD9revqef8SJWYMn0xLHw/7Eb2IwfcpEYbH4/xa037EtcTgu5VbSizLcmpwm+6e5/mjxIzh\n1cU2v/989M1qw3KfKw47Csn9lAjD4/F+KfDz7y03zrvqPATuqUwYjrAf8RkxYK8pw/AkEO9dNc2/\n83NEmjoMT1cF4vf3m9GV6/2ZnwfOKReGrbv+7HHV6bUznR/RYuOv+u9Me+XCcIW9txPbY8+/az2Q\nWu/6CwG/3TIMr7S8WKfFDKPHIUBBYEvJMJxZTrzT+mq+M/sVYkAVJcPQwxXnRezx14lWvU4MEgOO\n+tow/NR7oNozoLqyYWi5nNhy9jTskcSAK5UNQwXvBlvvcBj89CIMJ7SeYQgBo5QOw4jlxBlnQzHT\n78q9lQ7D7PaEQgyoqEQYvuWafhFgFuXu4ASMVyYMW5+m3zCTgGrKhAGoQxiAMEUYLCegr1JhsGs/\nH9G+p1Jh4D6uuNzcB8U4wgAEYQCCMABBGIAwTRjsfkM/5cJgJxrGKxcGYLypwmA5AX2UDIPlBIxV\nMgzAWNOFwXIC2isbBssJGKdsGIBxpgyD5QS0NWUYgLZKh8E+A4xROgx/sZyAdsqHwawB+isfBqA/\nYQCCMABhijDYZ4C+pggD0JcwAEEYgCAMQBAGIAgDEIQBCMIABGEAgjAAQRiAIAwMt3UtjJvxjCMM\nQBAGIAgDEIQBCMIABGHgFEcU7unf6AfAGD0G7quf4TZ9cxCGQb71E3VdV3GYgDB09q1BYC7C0JgQ\nJLOG+mw+NrKuqyhseBUFoajFjOEkg/+YowEwuxhjijBUG3zVHs8nrhxsW8+HAT2vKcJQxdVBMHCo\nShh2EAS+TfkwjJy2X/mzxYCZlA/DltYD7YooiMExy7LcYv/mDkqHoeem1pk3pAC05chEf6XD0Msn\nUfBG5c7KhmHURT7vCALfoGwYtlwxMD+NjijwLaYLw1lmCfBeyWslWi0jjn7fZVlEoTM3fqmh3Izh\nrzfAJ+fZHyUExznMeD/lwrDlyIAVhBocZpxXyaXEGaIA500zY3hHEOA604dBEOB6pcKw9xRo5yHc\n29Zmpj2LfkqF4S+uZYB+yoThr4FvhgB9lQnDlQQBzrnd4UpRgPNKzBjcFAVqKTFj+HRQP69lEIXx\nrr7GwTUTY5WYMewlANBHmTA8B/3PTwQhgDHKhOFJDGC8EnsMQC3CQFlmj+MIA9NxZKI9YQCCMABB\nGLiMk5LuQxiAIAxAEAYgCAMQhAEIwgAEYQCCMFCacyPGEAYuZSDfgzAAQRiAIAxAEAYgCAPl2dDs\nTxiAIAxAEAYgCAMQhIHL2SycnzAwBbHpSxiAIAxAEAYgCAMQhAEIwsA0HJnoRxiAIAw0sfXpzhyE\nAQjCAARhYCo2IPsQBiAIAxCEAQjCAARhAIIwMB0nT7UnDHTlsOIchAEIwgAEYQCCMABBGLgNG5vX\nEQYgCAMQhAEIwgAEYaCZljdVccOWtoQBCMIABGEAgjAAQRiAIAxMy5GJdoQBCMIABGGgKdP9OQkD\nEIQBCMLA1CxV2hAGIAgDEIQBCMIABGEAgjAwPUcmricMQBAGIAgDEIQBCMLALWxtQPIZYeDWHJn4\njDAAQRiAIAxAEAYgCAMQhAEIwgAEYQCCMABBGIAgDNyGG7ZcRxiAIAxAEAYgCAMQhAEIwgAEYQCC\nMABBGIAgDEAQBiAIAxCEgdtwsdR1hAEI/0Y/APjU3hmC/77uOGGgNMuDMYSBEloFwGzhM/YYaO7V\n4OwxYEXhc8LALYnCOYs1HPCbGQMQhAEIwgAEYQCCMABBGIAgDEAQBiAIAxCEAQjCAARhAIIwAEEY\ngCAMQBAGIAgDEIQBCMIABGEAgjAAQRiAIAxA+B9g3exw8VYVZgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1245decc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "axe_strokes = axe.loc[axe.index[0], 'drawing']\n",
    "img = draw_cv2(axe_strokes)\n",
    "\n",
    "plt.imshow(img, cmap=plt.cm.gray)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def df_to_image_array(df, size, lw=6):\n",
    "    x = np.zeros((len(df), size, size))\n",
    "    for i, raw_strokes in enumerate(df.drawing.values):\n",
    "        x[i] = draw_cv2(raw_strokes, size=size, lw=lw)\n",
    "    x = x / 255.\n",
    "    x = x.reshape((len(df), size, size)).astype(np.float32)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building our train and test functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first design our train and test functions. These functions can be used directly to train and test all the classification problems and all the architectures we will define in the whole notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model,data_loader,loss_fn,optimizer,n_epochs=1):\n",
    "    \n",
    "    model.train(True)\n",
    "    if use_gpu:\n",
    "        model.cuda()\n",
    "    \n",
    "    loss_train = np.zeros(n_epochs)\n",
    "    acc_train = np.zeros(n_epochs)\n",
    "    \n",
    "    for epoch_num in range(n_epochs):\n",
    "        running_corrects = 0.0\n",
    "        running_loss = 0.0\n",
    "        size = 0\n",
    "\n",
    "        for data in data_loader:\n",
    "            inputs, labels = data\n",
    "            bs = labels.size(0)\n",
    "            \n",
    "            if use_gpu:\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "        \n",
    "            outputs = model(inputs)        \n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_corrects += torch.sum(preds == labels)\n",
    "            running_loss += loss.data\n",
    "            \n",
    "            size += bs\n",
    "        \n",
    "        epoch_loss = running_loss / size\n",
    "        epoch_acc = running_corrects.item() / size\n",
    "        loss_train[epoch_num] = epoch_loss\n",
    "        acc_train[epoch_num] = epoch_acc\n",
    "        print('Train - Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "        \n",
    "    return loss_train, acc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(model,data_loader):\n",
    "    model.train(False)\n",
    "\n",
    "    running_corrects = 0.0\n",
    "    running_loss = 0.0\n",
    "    size = 0\n",
    "\n",
    "    for data in data_loader:\n",
    "        inputs, labels = data    \n",
    "        bs = labels.size(0)\n",
    "        \n",
    "        if use_gpu:\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "        \n",
    "        outputs = model(inputs)        \n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        running_corrects += torch.sum(preds == labels)\n",
    "        running_loss += loss.data\n",
    "         \n",
    "        size += bs\n",
    "\n",
    "    print('Test - Loss: {:.4f} Acc: {:.4f}'.format(running_loss / size, running_corrects.item() / size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_results(model,data_loader):\n",
    "    model.train(False)\n",
    "\n",
    "    running_corrects = 0.0\n",
    "    running_loss = 0.0\n",
    "    size = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for data in data_loader:\n",
    "        inputs, labels = data    \n",
    "        bs = labels.size(0)\n",
    "        \n",
    "        if use_gpu:\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "        \n",
    "        outputs = model(inputs)        \n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        running_corrects += torch.sum(preds == labels)\n",
    "        running_loss += loss.data\n",
    "        \n",
    "        preds = preds.cpu()\n",
    "        labels = labels.cpu()\n",
    "        \n",
    "        all_preds = np.append(all_preds, preds.numpy())\n",
    "        all_labels = np.append(all_labels, labels.numpy())\n",
    "         \n",
    "        size += bs\n",
    "        \n",
    "    return all_preds, all_labels\n",
    "\n",
    "    print('Test - Loss: {:.4f} Acc: {:.4f}'.format(running_loss / size, running_corrects.item() / size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_results(model, test_loader):\n",
    "    model.eval()\n",
    "\n",
    "    all_preds, all_labels = test_results(model,test_loader)\n",
    "\n",
    "    result_dic = {}\n",
    "    for key, value in mapping.items():\n",
    "        pred_of_class = all_preds[(all_labels == value)]\n",
    "        rate = sum(pred_of_class == value)/len(pred_of_class)\n",
    "        result_dic[key] = rate\n",
    "    \n",
    "    return result_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the architectures of the train and the test functions are ready. The only things we will need to change from now on will be the classifier function and the training and testing datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beginning with a multi-class classification problem : Axes, Ladders and Dolphins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "axe = pd.read_csv(os.path.join(data_dir, 'axe.csv'),\n",
    "                  index_col='key_id', \n",
    "                  nrows=1000).drop(['countrycode', 'recognized', 'timestamp'], axis=1)\n",
    "ladder = pd.read_csv(os.path.join(data_dir, 'ladder.csv'),\n",
    "                     index_col='key_id', \n",
    "                     nrows=1000).drop(['countrycode', 'recognized', 'timestamp'], axis=1)\n",
    "dolphin = pd.read_csv(os.path.join(data_dir, 'dolphin.csv'),\n",
    "                     index_col='key_id', \n",
    "                      nrows=1000).drop(['countrycode', 'recognized', 'timestamp'], axis=1)\n",
    "\n",
    "df_train = pd.concat([axe[:800], ladder[:800], dolphin[:800]], axis=0)\n",
    "df_test = pd.concat([axe[800:], ladder[800:], dolphin[800:]], axis=0)\n",
    "\n",
    "df_train.drawing = df_train.drawing.map(ast.literal_eval)\n",
    "df_test.drawing = df_test.drawing.map(ast.literal_eval)\n",
    "\n",
    "mapping = {'axe' : 0, \n",
    "           'ladder' : 1, \n",
    "           'dolphin' : 2}\n",
    "\n",
    "df_train.y = df_train.word.replace(mapping)\n",
    "df_test.y = df_test.word.replace(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 256, 256)\n",
      "(2400,)\n",
      "(600, 256, 256)\n",
      "(600,)\n"
     ]
    }
   ],
   "source": [
    "x_train = df_to_image_array(df=df_train, size=256)\n",
    "y_train = df_train.y\n",
    "\n",
    "x_test = df_to_image_array(df=df_test, size=256)\n",
    "y_test = df_test.y\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bs = 64 \n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_gpu else {}\n",
    "\n",
    "train_dataset = [[torch.from_numpy(e.astype(np.float32)).unsqueeze(0), \n",
    "                   torch.from_numpy(np.array(l).astype(np.int64))] for e, l in zip(x_train, y_train)]\n",
    "test_dataset = [[torch.from_numpy(e.astype(np.float32)).unsqueeze(0), \n",
    "                   torch.from_numpy(np.array(l).astype(np.int64))] for e, l in zip(x_test, y_test)]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=bs, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=bs, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building an very simple classifier with one Conv 2D Layer, one Max Pooling Layer and an activation function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class simple_classifier(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(simple_classifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3, padding=1)\n",
    "        self.fc = nn.Linear(in_features=4096, out_features=3)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.conv1(x)\n",
    "        x = F.max_pool2d(x, kernel_size=8, stride=8)\n",
    "        x = x.reshape(batch_size,4096)\n",
    "        x = self.fc(x)\n",
    "        x = F.log_softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samimhirech/anaconda/lib/python3.6/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/Users/samimhirech/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:14: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.5661 Acc: 0.7812\n",
      "Train - Loss: 0.3886 Acc: 0.8654\n",
      "Train - Loss: 0.3546 Acc: 0.8829\n",
      "Train - Loss: 0.3290 Acc: 0.8950\n",
      "Train - Loss: 0.3121 Acc: 0.8979\n"
     ]
    }
   ],
   "source": [
    "conv_class = simple_classifier()\n",
    "loss_fn = nn.NLLLoss(size_average=False)\n",
    "learning_rate = 1e-3\n",
    "optimizer_cl = torch.optim.SGD(conv_class.parameters(), lr=learning_rate)\n",
    "l_t, a_t = train(conv_class,train_loader,loss_fn,optimizer_cl,n_epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samimhirech/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:14: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test - Loss: 0.5622 Acc: 0.8183\n"
     ]
    }
   ],
   "source": [
    "test(conv_class,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samimhirech/anaconda/lib/python3.6/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type simple_classifier. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(conv_class, os.path.join(output_dir, 'model_3_1000.pt'))\n",
    "pickle.dump(mapping, open(os.path.join(output_dir,'map_3_1000.pickle'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samimhirech/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:14: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "results = get_results(conv_class, test_loader)\n",
    "pickle.dump(results, open(os.path.join(results_dir,'results_3_1000.pickle'), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Training for all csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_files = glob.glob(data_dir + \"/*.csv\")\n",
    "train_list = []\n",
    "test_list = []\n",
    "\n",
    "whole_size = 500\n",
    "train_size = 460\n",
    "\n",
    "for file in data_files:\n",
    "    df = pd.read_csv(file, \n",
    "                     index_col='key_id', \n",
    "                     nrows=whole_size).drop(['countrycode', 'recognized', 'timestamp'], axis=1)\n",
    "    train_list.append(df[:train_size])\n",
    "    test_list.append(df[train_size:])\n",
    "\n",
    "df_train = pd.concat(train_list, axis=0)\n",
    "df_test = pd.concat(test_list, axis=0)\n",
    "\n",
    "df_train.drawing = df_train.drawing.map(ast.literal_eval)\n",
    "df_test.drawing = df_test.drawing.map(ast.literal_eval)\n",
    "\n",
    "mapping = {x.replace(data_dir,'')[:-4]:i for i, x in enumerate(data_files)}\n",
    "num_classes = len(mapping)\n",
    "\n",
    "df_train.y = df_train.word.replace(mapping)\n",
    "df_test.y = df_test.word.replace(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train = df_to_image_array(df=df_train, size=96)\n",
    "y_train = df_train.y\n",
    "\n",
    "x_test = df_to_image_array(df=df_test, size=96)\n",
    "y_test = df_test.y\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bs = 64 \n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_gpu else {}\n",
    "\n",
    "train_dataset = [[torch.from_numpy(e.astype(np.float32)).unsqueeze(0), \n",
    "                   torch.from_numpy(np.array(l).astype(np.int64))] for e, l in zip(x_train, y_train)]\n",
    "test_dataset = [[torch.from_numpy(e.astype(np.float32)).unsqueeze(0), \n",
    "                   torch.from_numpy(np.array(l).astype(np.int64))] for e, l in zip(x_test, y_test)]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=bs, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=bs, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class classifier_all(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(classifier_all, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3, padding=1)\n",
    "        self.fc = nn.Linear(in_features=576, out_features=num_classes)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.conv1(x)\n",
    "        x = F.max_pool2d(x, kernel_size=8, stride=8)\n",
    "        x = x.reshape(batch_size,576)\n",
    "        x = self.fc(x)\n",
    "        x = F.log_softmax(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    classifier = classifier.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv_class_all = classifier_all()\n",
    "loss_fn = nn.NLLLoss(size_average=False)\n",
    "learning_rate = 1e-3\n",
    "optimizer_cl = torch.optim.SGD(conv_class_all.parameters(), lr=learning_rate)\n",
    "l_t, a_t = train(conv_class_all,train_loader,loss_fn,optimizer_cl,n_epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test(conv_class_all,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(conv_class_all, '../output/conv_all.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(mapping, open('../output/map_conv_all.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with customized ResNet 18 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dir_path = '../../data_quick_draw/'\n",
    "files = glob.glob(dir_path + \"/*.csv\")\n",
    "train_list = []\n",
    "test_list = []\n",
    "\n",
    "whole_size = 500\n",
    "train_size = 460\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(file, \n",
    "                     index_col='key_id', \n",
    "                     nrows=whole_size).drop(['countrycode', 'recognized', 'timestamp'], axis=1)\n",
    "    train_list.append(df[:train_size])\n",
    "    test_list.append(df[train_size:])\n",
    "\n",
    "df_train = pd.concat(train_list, axis=0)\n",
    "df_test = pd.concat(test_list, axis=0)\n",
    "\n",
    "df_train.drawing = df_train.drawing.map(ast.literal_eval)\n",
    "df_test.drawing = df_test.drawing.map(ast.literal_eval)\n",
    "\n",
    "mapping = {x.replace('../../data_quick_draw/','').replace(\" \",\"_\")[:-4]:i for i, x in enumerate(files)}\n",
    "num_classes = len(mapping)\n",
    "\n",
    "df_train.y = df_train.word.replace(mapping)\n",
    "df_test.y = df_test.word.replace(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train = df_to_image_array(df=df_train, size=224)\n",
    "y_train = df_train.y\n",
    "\n",
    "x_test = df_to_image_array(df=df_test, size=224)\n",
    "y_test = df_test.y\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bs = 64 \n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_gpu else {}\n",
    "\n",
    "train_dataset = [[torch.from_numpy(e.astype(np.float32)).unsqueeze(0), \n",
    "                   torch.from_numpy(np.array(l).astype(np.int64))] for e, l in zip(x_train, y_train)]\n",
    "test_dataset = [[torch.from_numpy(e.astype(np.float32)).unsqueeze(0), \n",
    "                   torch.from_numpy(np.array(l).astype(np.int64))] for e, l in zip(x_test, y_test)]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=bs, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=bs, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class classifier_resnet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(classifier_resnet,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, stride=2, padding=3)\n",
    "        # Downloading architecture of resnet18\n",
    "        self.resnet = models.resnet18(pretrained=False)\n",
    "        # Deleting last layer of resnet18 because it has out_features = 1000 by default (the 1000 classes of ImageNet)\n",
    "        self.base = nn.Sequential(*list(self.resnet.children())[1:-1])\n",
    "        # Adding FC layer\n",
    "        self.fc = nn.Linear(2048,num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.conv1(x)\n",
    "        x = self.base(x)\n",
    "        x = x.reshape(batch_size, -1)\n",
    "        x = self.fc(x)\n",
    "        x = F.log_softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resnet_model = classifier_resnet()\n",
    "loss_fn = nn.NLLLoss(size_average=False)\n",
    "learning_rate = 1e-3\n",
    "optimizer_cl = torch.optim.SGD(resnet_model.parameters(), lr=learning_rate)\n",
    "l_t, a_t = train(resnet_model,train_loader,loss_fn,optimizer_cl,n_epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test(resnet_model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(resnet_model, '../output/model_resnet.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(mapping, open('../output/map_resnet.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with architecture of a Kaggler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dir_path = '../../data_quick_draw/'\n",
    "files = glob.glob(dir_path + \"/*.csv\")\n",
    "train_list = []\n",
    "test_list = []\n",
    "\n",
    "whole_size = 500\n",
    "train_size = 460\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(file, \n",
    "                     index_col='key_id', \n",
    "                     nrows=whole_size).drop(['countrycode', 'recognized', 'timestamp'], axis=1)\n",
    "    train_list.append(df[:train_size])\n",
    "    test_list.append(df[train_size:])\n",
    "\n",
    "df_train = pd.concat(train_list, axis=0)\n",
    "df_test = pd.concat(test_list, axis=0)\n",
    "\n",
    "df_train.drawing = df_train.drawing.map(ast.literal_eval)\n",
    "df_test.drawing = df_test.drawing.map(ast.literal_eval)\n",
    "\n",
    "mapping = {x.replace('../../data_quick_draw/','').replace(\" \",\"_\")[:-4]:i for i, x in enumerate(files)}\n",
    "num_classes = len(mapping)\n",
    "\n",
    "df_train.y = df_train.word.replace(mapping)\n",
    "df_test.y = df_test.word.replace(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train = df_to_image_array(df=df_train, size=32)\n",
    "y_train = df_train.y\n",
    "\n",
    "x_test = df_to_image_array(df=df_test, size=32)\n",
    "y_test = df_test.y\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bs = 64 \n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_gpu else {}\n",
    "\n",
    "train_dataset = [[torch.from_numpy(e.astype(np.float32)).unsqueeze(0), \n",
    "                   torch.from_numpy(np.array(l).astype(np.int64))] for e, l in zip(x_train, y_train)]\n",
    "test_dataset = [[torch.from_numpy(e.astype(np.float32)).unsqueeze(0), \n",
    "                   torch.from_numpy(np.array(l).astype(np.int64))] for e, l in zip(x_test, y_test)]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=bs, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=bs, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class classifier_kaggle(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(classifier_kaggle,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3)\n",
    "        self.dense1 = nn.Linear(3136, 1024)\n",
    "        self.dense2 = nn.Linear(1024, num_classes)\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.conv1(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        x = self.conv2(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        x = x.reshape(batch_size, -1)\n",
    "        x = self.dense1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dense2(x)\n",
    "        x = F.log_softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kaggle_model = classifier_kaggle()\n",
    "loss_fn = nn.NLLLoss(size_average=False)\n",
    "learning_rate = 1e-3\n",
    "optimizer_cl = torch.optim.SGD(kaggle_model.parameters(), lr=learning_rate)\n",
    "l_t, a_t = train(kaggle_model,train_loader,loss_fn,optimizer_cl,n_epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test(kaggle_model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.save(kaggle_model, '../output/model_kaggle.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(mapping, open('../output/map_kaggle.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding results on test sets by label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "all_preds, all_labels = test_results(model,test_loader)\n",
    "\n",
    "result_dic = {}\n",
    "for key, value in mapping.items():\n",
    "    pred_of_class = all_preds[(all_labels == value)]\n",
    "    rate = sum(pred_of_class == value)/len(pred_of_class)\n",
    "    result_dic[key] = rate\n",
    "\n",
    "pickle.dump(result_dic, open('/content/drive/My Drive/QuickDraw/output/results_340_2000.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainining models on GPU "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our dataset is composed of 50 million drawings and that we do not have any GPU on our computers, we have decided to train our models on Google Colaboratory and use their GPU. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A part of our preprocessing is done with pandas, which stores the data on the RAM, so we were not able to load all the data on Google Colab since it proposes a limited RAM of 12.7 Go. So we tried different experiments and trainings to test the limits of Google Colab's RAM. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20 labels and 20000 images by label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Training set : 20000 images by label\n",
    "- Testing set : 5000 images by label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = pickle.load(open('../output/results_20_25000.pickle', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(pd.Series(results)).reset_index()\n",
    "results_df.columns = ['label', 'perc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_df.sort_values('perc', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_df.sort_values('perc')[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 114 labels and 460 images by label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Training set : 460 images by label\n",
    "- Testing set : 40 images by label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = pickle.load(open('../output/results_114_500.pickle', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(pd.Series(results)).reset_index()\n",
    "results_df.columns = ['label', 'perc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_df.sort_values('perc', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_df.sort_values('perc')[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 114 labels and 3000 images "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Training set : 3000 images by label\n",
    "- Testing set : 500 images by label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = pickle.load(open('../output/results_114_3500.pickle', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(pd.Series(results)).reset_index()\n",
    "results_df.columns = ['label', 'perc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_df.sort_values('perc', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_df.sort_values('perc')[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 340 labels and 800 images "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Training set : 800 images by label\n",
    "- Testing set : 200 images by label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = pickle.load(open('../output/results_340_1000.pickle', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(pd.Series(results)).reset_index()\n",
    "results_df.columns = ['label', 'perc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_df.sort_values('perc', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_df.sort_values('perc')[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 340 labels and 1600 images "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Training set : 1600 images by label\n",
    "- Testing set : 400 images by label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = [2.8013, 1.9212, 1.6502, 1.4501, 1.2705, 1.0988, 0.9333, 0.7790, 0.6497, 0.5403]\n",
    "accuracy = [0.3895, 0.5487, 0.6040, 0.6459, 0.6829, 0.7200, 0.7561, 0.7918, 0.8200, 0.8459]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(np.arange(0,10), loss)\n",
    "plt.ylabel('NLLLoss')\n",
    "plt.xlabel('Epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(np.arange(0,10), accuracy)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = pickle.load(open('../output/results_340_2000.pickle', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(pd.Series(results)).reset_index()\n",
    "results_df.columns = ['label', 'perc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_df.sort_values('perc', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_df.sort_values('perc')[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model with one image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ex_path = '../../data_quick_draw/dolphin.csv'\n",
    "\n",
    "ex_df = pd.read_csv(ex_path, index_col='key_id', nrows=3).drop(['countrycode', 'recognized', 'timestamp'], axis=1)\n",
    "\n",
    "ex_df.drawing = ex_df.drawing.map(ast.literal_eval)\n",
    "\n",
    "plt.imshow(draw_cv2(ex_df.loc[ex_df.index[1], 'drawing']))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapping = pickle.load(open('/content/drive/My Drive/QuickDraw/output/map_340_2000.pickle', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ex_input = torch.from_numpy(draw_cv2(ex_strokes, size = 32).astype(np.float32)).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model(ex_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be continued ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
