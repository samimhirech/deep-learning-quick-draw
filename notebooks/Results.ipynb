{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "B40TWycFK-5z"
   },
   "source": [
    "# Building a Neural Network to recognize Quick Draw doodles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GYoR3vNlK-51"
   },
   "source": [
    "The general idea of this notebook will be to try and test the solutions provided by Google AI and other kagglers to the classification problem linked to the Quick Draw dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pxXq_fRAK-51"
   },
   "source": [
    "## Google AI suggestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cvr8Ex8YK-52"
   },
   "source": [
    "Building a Neural Network dataset introducting LSTM layers. Indeed, they want to take into account the notion of temporality by using layers that keep track of what happened before. They also do not want to use a Neural Network that would consider the input as an image by using 1D Convolutionnal Layers. It's worth a try ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GjvLczhFK-53"
   },
   "source": [
    "Tutorial of Google AI's solution in Tensorflow right here : https://www.tensorflow.org/tutorials/sequences/recurrent_quickdraw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1b6QXguFK-53"
   },
   "source": [
    "## Considering the dataset as images only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xd__KFhhK-57"
   },
   "source": [
    "A simpler idea would consist in interpreting the vectors of coordinates of the dataset as images only. Thus, we could use classical Neural Networks architectures that would consist in a succession of 2D Convolutionnal Layers and Max Pooling Layers, ending with a Flatten Layer then a FC layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t4AC98FiK-57"
   },
   "source": [
    "Exemple of such a solution in Tensorflow here : https://www.kaggle.com/gaborfodor/black-white-cnn-lb-0-75/notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VU9AnMc4K-58"
   },
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aXVS_s0fK-5-"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "#from tqdm import tqdm_notebook\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import models,transforms,datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "#tqdm_notebook().pandas()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5pjEJSQjK-6P"
   },
   "source": [
    "## Transforming data to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e-ZazRSfK-6Q"
   },
   "outputs": [],
   "source": [
    "BASE_SIZE = 256\n",
    "\n",
    "def draw_cv2(raw_strokes, size=256, lw=6):\n",
    "    img = np.zeros((BASE_SIZE, BASE_SIZE), np.uint8)\n",
    "    for stroke in raw_strokes:\n",
    "        for i in range(len(stroke[0]) - 1):\n",
    "            _ = cv2.line(img, (stroke[0][i], stroke[1][i]), (stroke[0][i + 1], stroke[1][i + 1]), 255, lw)\n",
    "    if size != BASE_SIZE:\n",
    "        return cv2.resize(img, (size, size))\n",
    "    else:\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6ZGCJ27cK-6V"
   },
   "outputs": [],
   "source": [
    "def df_to_image_array(df, size, lw=6):\n",
    "    x = np.zeros((len(df), size, size))\n",
    "    for i, raw_strokes in enumerate(df.drawing.values):\n",
    "        x[i] = draw_cv2(raw_strokes, size=size, lw=lw)\n",
    "    x = x / 255.\n",
    "    x = x.reshape((len(df), size, size)).astype(np.float32)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Neural Network of a Kaggler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-W6aFqu2K-7y"
   },
   "outputs": [],
   "source": [
    "class classifier_kaggle(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(classifier_kaggle,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3)\n",
    "        self.dense1 = nn.Linear(3136, 1024)\n",
    "        self.dense2 = nn.Linear(1024, num_classes)\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.conv1(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        x = self.conv2(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        x = x.reshape(batch_size, -1)\n",
    "        x = self.dense1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dense2(x)\n",
    "        x = F.log_softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,data_loader):\n",
    "    model.train(False)\n",
    "\n",
    "    running_corrects = 0.0\n",
    "    running_loss = 0.0\n",
    "    size = 0\n",
    "\n",
    "    for data in data_loader:\n",
    "        inputs, labels = data    \n",
    "        bs = labels.size(0)\n",
    "        \n",
    "        if use_gpu:\n",
    "            inputs.cuda()\n",
    "        \n",
    "        outputs = model(inputs)        \n",
    "        loss = loss_fn(outputs, labels)\n",
    "        print(\"outputs\", outputs)\n",
    "        print('labels', labels)\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        running_corrects += torch.sum(preds == labels.data.type(torch.LongTensor))\n",
    "        running_loss += loss.data\n",
    "         \n",
    "        size += bs\n",
    "\n",
    "    print('Test - Loss: {:.4f} Acc: {:.4f}'.format(running_loss / size, running_corrects.item() / size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CKNGxrenK-6l"
   },
   "outputs": [],
   "source": [
    "def train(model,data_loader,loss_fn,optimizer,n_epochs=1):\n",
    "    \n",
    "    model.train(True)\n",
    "    \n",
    "    loss_train = np.zeros(n_epochs)\n",
    "    acc_train = np.zeros(n_epochs)\n",
    "    \n",
    "    for epoch_num in range(n_epochs):\n",
    "        running_corrects = 0.0\n",
    "        running_loss = 0.0\n",
    "        size = 0\n",
    "\n",
    "        for data in data_loader:\n",
    "            inputs, labels = data\n",
    "            bs = labels.size(0)\n",
    "            \n",
    "            if use_gpu:\n",
    "                inputs.cuda()\n",
    "        \n",
    "            outputs = model(inputs)        \n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_corrects += torch.sum(preds == labels.data.type(torch.LongTensor))\n",
    "            running_loss += loss.data\n",
    "            \n",
    "            size += bs\n",
    "        \n",
    "        epoch_loss = running_loss / size\n",
    "        epoch_acc = running_corrects.item() / size\n",
    "        loss_train[epoch_num] = epoch_loss\n",
    "        acc_train[epoch_num] = epoch_acc\n",
    "        print('Train - Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "        \n",
    "    return loss_train, acc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,data_loader):\n",
    "    model.train(False)\n",
    "\n",
    "    running_corrects = 0.0\n",
    "    running_loss = 0.0\n",
    "    size = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for data in data_loader:\n",
    "        inputs, labels = data    \n",
    "        bs = labels.size(0)\n",
    "        \n",
    "        if use_gpu:\n",
    "            inputs.cuda()\n",
    "        \n",
    "        outputs = model(inputs)        \n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        running_corrects += torch.sum(preds == labels.data.type(torch.LongTensor))\n",
    "        running_loss += loss.data\n",
    "        \n",
    "        all_preds = np.append(all_preds, preds.numpy())\n",
    "        all_labels = np.append(all_labels, labels.numpy())\n",
    "         \n",
    "        size += bs\n",
    "        \n",
    "    return all_preds, all_labels\n",
    "\n",
    "    print('Test - Loss: {:.4f} Acc: {:.4f}'.format(running_loss / size, running_corrects.item() / size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xXm1FEwFK-7i"
   },
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO BE FILLED IN\n",
    "PATH_TO_DATA = \"..\\\\data\\\\train_simplified\\\\\"\n",
    "PATH_TO_MAPPING = \"..\\\\output\\\\map.p\"\n",
    "PATH_TO_MODEL = \"..\\\\output\\\\model_kaggle.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = pickle.load(open(PATH_TO_MAPPING, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We trained our model on 114 classes, with 460 images per class.\n"
     ]
    }
   ],
   "source": [
    "# USED DATA\n",
    "whole_size = 500\n",
    "train_size = 460\n",
    "print(\"We trained our model on {} classes, with {} images per class.\".format(len(mapping), train_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "for key in mapping.keys():\n",
    "    file = PATH_TO_DATA + key + \".csv\"\n",
    "    files.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "09BklFEGK-7m"
   },
   "outputs": [],
   "source": [
    "train_list = []\n",
    "test_list = []\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(file, \n",
    "                     index_col='key_id', \n",
    "                     nrows=whole_size).drop(['countrycode', 'recognized', 'timestamp'], axis=1)\n",
    "    train_list.append(df[:train_size])\n",
    "    test_list.append(df[train_size:])\n",
    "\n",
    "df_train = pd.concat(train_list, axis=0)\n",
    "df_test = pd.concat(test_list, axis=0)\n",
    "\n",
    "df_train.drawing = df_train.drawing.map(ast.literal_eval)\n",
    "df_test.drawing = df_test.drawing.map(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_x3_XHfDTxDE"
   },
   "outputs": [],
   "source": [
    "df_train.y = df_train.word.replace(mapping)\n",
    "df_test.y = df_test.word.replace(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6921,
     "status": "ok",
     "timestamp": 1539886579345,
     "user": {
      "displayName": "Simon PAGEZY",
      "photoUrl": "",
      "userId": "05378704956293797209"
     },
     "user_tz": -120
    },
    "id": "sBZ0LcwUK-7p",
    "outputId": "1e9965f9-a07c-4e20-8055-8ef3b7fc3615"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52440, 32, 32)\n",
      "(52440,)\n",
      "(4560, 32, 32)\n",
      "(4560,)\n"
     ]
    }
   ],
   "source": [
    "x_train = df_to_image_array(df=df_train, size=32)\n",
    "y_train = df_train.y\n",
    "\n",
    "x_test = df_to_image_array(df=df_test, size=32)\n",
    "y_test = df_test.y\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zQl_C7LpUdZ6"
   },
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y-EK3v4lK-7u"
   },
   "outputs": [],
   "source": [
    "bs = 64 \n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_gpu else {}\n",
    "\n",
    "train_dataset = [[torch.from_numpy(e.astype(np.float32)).unsqueeze(0), \n",
    "                   torch.from_numpy(np.array(l).astype(np.int64))] for e, l in zip(x_train, y_train)]\n",
    "test_dataset = [[torch.from_numpy(e.astype(np.float32)).unsqueeze(0), \n",
    "                   torch.from_numpy(np.array(l).astype(np.int64))] for e, l in zip(x_test, y_test)]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=bs, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=bs, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classifier_kaggle(\n",
       "  (conv1): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (dense1): Linear(in_features=3136, out_features=1024, bias=True)\n",
       "  (dense2): Linear(in_features=1024, out_features=114, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(PATH_TO_MODEL)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2548762,
     "status": "ok",
     "timestamp": 1539889240541,
     "user": {
      "displayName": "Simon PAGEZY",
      "photoUrl": "",
      "userId": "05378704956293797209"
     },
     "user_tz": -120
    },
    "id": "Kxe_0dDJK-7z",
    "outputId": "b8c9fa8e-2b1a-42a9-a8e7-7a64692e8c8a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\simon\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.NLLLoss(size_average=False)\n",
    "learning_rate = 1e-3\n",
    "#optimizer_cl = torch.optim.SGD(kaggle_model.parameters(), lr=learning_rate)\n",
    "#l_t, a_t = train(kaggle_model,train_loader,loss_fn,optimizer_cl,n_epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11140,
     "status": "ok",
     "timestamp": 1539889939843,
     "user": {
      "displayName": "Simon PAGEZY",
      "photoUrl": "",
      "userId": "05378704956293797209"
     },
     "user_tz": -120
    },
    "id": "rS9JE8S1K-72",
    "outputId": "9cf07559-67d1-4545-9cc5-d69943f9d35d",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\simon\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "all_preds, all_labels = test(model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dic = {}\n",
    "for key, value in mapping.items():\n",
    "    pred_of_class = all_preds[(all_labels == value)]\n",
    "    rate = sum(pred_of_class == value)/len(pred_of_class)\n",
    "    result_dic[key] = rate\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cookie': 0.525,\n",
       " 'computer': 0.75,\n",
       " 'compass': 0.775,\n",
       " 'coffee cup': 0.5,\n",
       " 'cloud': 0.65,\n",
       " 'clock': 0.25,\n",
       " 'clarinet': 0.425,\n",
       " 'circle': 0.725,\n",
       " 'church': 0.525,\n",
       " 'chandelier': 0.45,\n",
       " 'chair': 0.8,\n",
       " 'cello': 0.775,\n",
       " 'cell phone': 0.65,\n",
       " 'ceiling fan': 0.475,\n",
       " 'cat': 0.425,\n",
       " 'castle': 0.475,\n",
       " 'carrot': 0.575,\n",
       " 'car': 0.55,\n",
       " 'canoe': 0.75,\n",
       " 'cannon': 0.55,\n",
       " 'candle': 0.65,\n",
       " 'campfire': 0.6,\n",
       " 'camouflage': 0.175,\n",
       " 'camera': 0.65,\n",
       " 'camel': 0.6,\n",
       " 'calendar': 0.55,\n",
       " 'calculator': 0.6,\n",
       " 'cake': 0.3,\n",
       " 'cactus': 0.45,\n",
       " 'butterfly': 0.775,\n",
       " 'bush': 0.325,\n",
       " 'bus': 0.75,\n",
       " 'bulldozer': 0.65,\n",
       " 'bucket': 0.85,\n",
       " 'broom': 0.775,\n",
       " 'broccoli': 0.65,\n",
       " 'bridge': 0.525,\n",
       " 'bread': 0.5,\n",
       " 'brain': 0.5,\n",
       " 'bracelet': 0.4,\n",
       " 'bowtie': 0.85,\n",
       " 'bottlecap': 0.275,\n",
       " 'boomerang': 0.425,\n",
       " 'book': 0.525,\n",
       " 'blueberry': 0.35,\n",
       " 'blackberry': 0.375,\n",
       " 'birthday cake': 0.575,\n",
       " 'bird': 0.175,\n",
       " 'binoculars': 0.35,\n",
       " 'bicycle': 0.775,\n",
       " 'bench': 0.55,\n",
       " 'belt': 0.6,\n",
       " 'bee': 0.4,\n",
       " 'bed': 0.425,\n",
       " 'beard': 0.65,\n",
       " 'bear': 0.45,\n",
       " 'beach': 0.75,\n",
       " 'bathtub': 0.4,\n",
       " 'bat': 0.55,\n",
       " 'basketball': 0.7,\n",
       " 'basket': 0.65,\n",
       " 'baseball': 0.475,\n",
       " 'baseball bat': 0.75,\n",
       " 'barn': 0.475,\n",
       " 'bandage': 0.825,\n",
       " 'banana': 0.775,\n",
       " 'backpack': 0.525,\n",
       " 'axe': 0.775,\n",
       " 'asparagus': 0.5,\n",
       " 'arm': 0.2,\n",
       " 'apple': 0.9,\n",
       " 'anvil': 0.8,\n",
       " 'ant': 0.325,\n",
       " 'animal migration': 0.45,\n",
       " 'angel': 0.625,\n",
       " 'ambulance': 0.5,\n",
       " 'alarm clock': 0.25,\n",
       " 'airplane': 0.55,\n",
       " 'cooler': 0.125,\n",
       " 'couch': 0.525,\n",
       " 'cow': 0.425,\n",
       " 'crab': 0.575,\n",
       " 'crayon': 0.3,\n",
       " 'crocodile': 0.375,\n",
       " 'crown': 0.875,\n",
       " 'cruise ship': 0.65,\n",
       " 'cup': 0.4,\n",
       " 'diamond': 0.7,\n",
       " 'dishwasher': 0.325,\n",
       " 'diving board': 0.4,\n",
       " 'dog': 0.275,\n",
       " 'dolphin': 0.425,\n",
       " 'donut': 0.8,\n",
       " 'door': 0.825,\n",
       " 'dragon': 0.3,\n",
       " 'dresser': 0.4,\n",
       " 'drill': 0.35,\n",
       " 'drums': 0.425,\n",
       " 'duck': 0.425,\n",
       " 'dumbbell': 0.65,\n",
       " 'ear': 0.725,\n",
       " 'elbow': 0.5,\n",
       " 'elephant': 0.425,\n",
       " 'envelope': 0.9,\n",
       " 'eraser': 0.25,\n",
       " 'eye': 0.725,\n",
       " 'eyeglasses': 0.675,\n",
       " 'face': 0.6,\n",
       " 'fan': 0.45,\n",
       " 'feather': 0.575,\n",
       " 'fence': 0.575,\n",
       " 'finger': 0.625,\n",
       " 'fire hydrant': 0.45,\n",
       " 'fireplace': 0.6}"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dic"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Ue9spIxiK-62",
    "Erla3b0gK-7Q"
   ],
   "name": "scrapbook.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
